package rag

import (
	"fmt"
	"path/filepath"
	"strings"
	"time"

	"notion-lite/internal/document"
	"notion-lite/internal/fileextract"
	"notion-lite/internal/opengraph"
)

// ExternalIndexer handles indexing of external content (bookmarks and files)
type ExternalIndexer struct {
	store      *VectorStore
	embedder   EmbeddingClient
	docRepo    *document.Repository
	docStorage *document.Storage
	indexer    *Indexer
	dataPath   string
}

// NewExternalIndexer creates a new external content indexer
func NewExternalIndexer(
	store *VectorStore,
	embedder EmbeddingClient,
	docRepo *document.Repository,
	docStorage *document.Storage,
	indexer *Indexer,
	dataPath string,
) *ExternalIndexer {
	return &ExternalIndexer{
		store:      store,
		embedder:   embedder,
		docRepo:    docRepo,
		docStorage: docStorage,
		indexer:    indexer,
		dataPath:   dataPath,
	}
}

// IndexBookmarkContent ç´¢å¼•ä¹¦ç­¾ç½‘é¡µå†…å®¹ï¼ˆåˆ†å—å­˜å‚¨ï¼‰
func (e *ExternalIndexer) IndexBookmarkContent(url, sourceDocID, blockID string) error {
	// 1. æŠ“å–ç½‘é¡µå†…å®¹
	content, err := opengraph.FetchContent(url)
	if err != nil {
		return fmt.Errorf("failed to fetch content: %w", err)
	}

	// 2. æ£€æŸ¥å†…å®¹æ˜¯å¦ä¸ºç©º
	if content.TextContent == "" {
		return fmt.Errorf("no content extracted from URL")
	}

	// 3. æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯
	headingContext := content.Title
	if content.SiteName != "" {
		headingContext = fmt.Sprintf("%s - %s", content.Title, content.SiteName)
	}

	// 4. ç”ŸæˆåŸºç¡€ ID
	baseID := fmt.Sprintf("%s_%s_bookmark", sourceDocID, blockID)

	// 5. åˆ é™¤è¯¥ bookmark block çš„æ—§ chunksï¼ˆä¿®å¤é‡æ–°ç´¢å¼•æ—¶çš„ä¸»é”®å†²çªï¼‰
	if err := e.store.DeleteBlocksByPrefix(baseID); err != nil {
		fmt.Printf("âš ï¸ [RAG] Failed to delete old bookmark chunks for %s: %v\n", baseID, err)
	}

	// 5.1 ä¿å­˜å®Œæ•´æå–å†…å®¹ï¼ˆä¾› MCP å·¥å…·è¯»å–ï¼‰
	if err := e.store.SaveExternalContent(&ExternalBlockContent{
		ID:          fmt.Sprintf("%s_%s", sourceDocID, blockID),
		DocID:       sourceDocID,
		BlockID:     blockID,
		BlockType:   "bookmark",
		URL:         url,
		Title:       content.Title,
		RawContent:  content.TextContent,
		ExtractedAt: time.Now().Unix(),
	}); err != nil {
		fmt.Printf("âš ï¸ [RAG] Failed to save bookmark content for %s: %v\n", baseID, err)
	}

	// 6. å¯¹å†…å®¹è¿›è¡Œåˆ†å—
	chunks := ChunkTextContent(content.TextContent, headingContext, baseID, e.indexer.chunkConfig)

	// å¦‚æœåˆ†å—ç»“æœä¸ºç©ºï¼Œåˆ›å»ºä¸€ä¸ªå•ç‹¬çš„å—
	if len(chunks) == 0 {
		chunks = []ExtractedBlock{{
			ID:             baseID,
			Type:           "bookmark",
			Content:        content.TextContent,
			HeadingContext: headingContext,
		}}
	}

	// è°ƒè¯•è¾“å‡º
	if debugChunks {
		fmt.Printf("\nğŸ”– [RAG] Indexing bookmark: %s\n", url)
		fmt.Printf("   Title: %s\n", content.Title)
		fmt.Printf("   Total chunks: %d\n", len(chunks))
		fmt.Println("   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
		for i, chunk := range chunks {
			fmt.Printf("   [%d] ID: %s\n", i, chunk.ID)
			fmt.Printf("       Content (%4d chars): %s\n",
				len(chunk.Content), truncateContent(chunk.Content, 80))
		}
		fmt.Println("   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
	}

	// 7. ä¸ºæ¯ä¸ª chunk ç”Ÿæˆ embedding å¹¶å­˜å‚¨
	successCount := 0
	failedCount := 0
	var lastError error
	for _, chunk := range chunks {
		if chunk.Content == "" {
			continue
		}

		embedding, err := e.embedder.Embed(chunk.Content)
		if err != nil {
			failedCount++
			lastError = err
			fmt.Printf("âš ï¸ [RAG] Failed to embed bookmark chunk %s: %v\n", chunk.ID, err)
			continue // è·³è¿‡å¤±è´¥çš„å—
		}

		contentHash := HashContent(chunk.Content)
		if err := e.store.Upsert(&BlockVector{
			ID:             chunk.ID,
			SourceBlockID:  blockID, // BookmarkBlock çš„ BlockNote IDï¼Œç”¨äºå®šä½
			DocID:          sourceDocID,
			Content:        chunk.Content,
			ContentHash:    contentHash,
			BlockType:      "bookmark",
			HeadingContext: chunk.HeadingContext,
			Embedding:      embedding,
		}); err != nil {
			fmt.Printf("âš ï¸ [RAG] Failed to upsert bookmark chunk %s: %v\n", chunk.ID, err)
			failedCount++
		} else {
			successCount++
		}
	}

	// å¦‚æœæ‰€æœ‰ chunks éƒ½åµŒå…¥å¤±è´¥ï¼Œè¿”å›é”™è¯¯
	if successCount == 0 && failedCount > 0 {
		return fmt.Errorf("embedding failed: %v", lastError)
	}

	return nil
}

// IndexFileContent ç´¢å¼•æ–‡ä»¶å†…å®¹ï¼ˆåˆ†å—å­˜å‚¨ï¼‰
func (e *ExternalIndexer) IndexFileContent(filePath, sourceDocID, blockID string) error {
	// 1. è·å–å®Œæ•´æ–‡ä»¶è·¯å¾„
	fullPath := filepath.Join(e.dataPath, strings.TrimPrefix(filePath, "/"))

	// 2. æå–æ–‡æœ¬å†…å®¹
	textContent, err := fileextract.ExtractText(fullPath)
	if err != nil {
		return fmt.Errorf("failed to extract text: %w", err)
	}

	if textContent == "" {
		return fmt.Errorf("no text content extracted from file")
	}

	// 3. æ„å»ºä¸Šä¸‹æ–‡ï¼ˆä½¿ç”¨æ–‡ä»¶åï¼‰
	fileName := filepath.Base(fullPath)
	headingContext := fileName

	// 4. ç”ŸæˆåŸºç¡€ ID
	baseID := fmt.Sprintf("%s_%s_file", sourceDocID, blockID)

	// 5. åˆ é™¤è¯¥ file block çš„æ—§ chunksï¼ˆä¿®å¤é‡æ–°ç´¢å¼•æ—¶çš„ä¸»é”®å†²çªï¼‰
	if err := e.store.DeleteBlocksByPrefix(baseID); err != nil {
		fmt.Printf("âš ï¸ [RAG] Failed to delete old file chunks for %s: %v\n", baseID, err)
	}

	// 5.1 ä¿å­˜å®Œæ•´æå–å†…å®¹ï¼ˆä¾› MCP å·¥å…·è¯»å–ï¼‰
	if err := e.store.SaveExternalContent(&ExternalBlockContent{
		ID:          fmt.Sprintf("%s_%s", sourceDocID, blockID),
		DocID:       sourceDocID,
		BlockID:     blockID,
		BlockType:   "file",
		FilePath:    filePath,
		Title:       fileName,
		RawContent:  textContent,
		ExtractedAt: time.Now().Unix(),
	}); err != nil {
		fmt.Printf("âš ï¸ [RAG] Failed to save file content for %s: %v\n", baseID, err)
	}

	// 6. å¯¹å†…å®¹è¿›è¡Œåˆ†å—
	chunks := ChunkTextContent(textContent, headingContext, baseID, e.indexer.chunkConfig)

	// å¦‚æœåˆ†å—ç»“æœä¸ºç©ºï¼Œåˆ›å»ºä¸€ä¸ªå•ç‹¬çš„å—
	if len(chunks) == 0 {
		chunks = []ExtractedBlock{{
			ID:             baseID,
			Type:           "file",
			Content:        textContent,
			HeadingContext: headingContext,
		}}
	}

	// è°ƒè¯•è¾“å‡º
	if debugChunks {
		fmt.Printf("\nğŸ“„ [RAG] Indexing file: %s\n", fileName)
		fmt.Printf("   Total chunks: %d\n", len(chunks))
		fmt.Println("   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
		for i, chunk := range chunks {
			fmt.Printf("   [%d] ID: %s\n", i, chunk.ID)
			fmt.Printf("       Content (%4d chars): %s\n",
				len(chunk.Content), truncateContent(chunk.Content, 80))
		}
		fmt.Println("   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
	}

	// 7. ä¸ºæ¯ä¸ª chunk ç”Ÿæˆ embedding å¹¶å­˜å‚¨
	successCount := 0
	failedCount := 0
	var lastError error
	for _, chunk := range chunks {
		if chunk.Content == "" {
			continue
		}

		embedding, err := e.embedder.Embed(chunk.Content)
		if err != nil {
			failedCount++
			lastError = err
			fmt.Printf("âš ï¸ [RAG] Failed to embed file chunk %s: %v\n", chunk.ID, err)
			continue // è·³è¿‡å¤±è´¥çš„å—
		}

		contentHash := HashContent(chunk.Content)
		if err := e.store.Upsert(&BlockVector{
			ID:             chunk.ID,
			SourceBlockID:  blockID, // FileBlock çš„ BlockNote IDï¼Œç”¨äºå®šä½
			DocID:          sourceDocID,
			Content:        chunk.Content,
			ContentHash:    contentHash,
			BlockType:      "file",
			HeadingContext: chunk.HeadingContext,
			FilePath:       filePath, // å­˜å‚¨æ–‡ä»¶è·¯å¾„ï¼Œç”¨äºåˆ é™¤æ—¶æ¸…ç†ç‰©ç†æ–‡ä»¶
			Embedding:      embedding,
		}); err != nil {
			fmt.Printf("âŒ [RAG] Failed to upsert file chunk %s: %v\n", chunk.ID, err)
			failedCount++
		} else {
			successCount++
			if debugChunks {
				fmt.Printf("âœ… [RAG] Stored file chunk: %s\n", chunk.ID)
			}
		}
	}

	// å¦‚æœæ‰€æœ‰ chunks éƒ½åµŒå…¥å¤±è´¥ï¼Œè¿”å›é”™è¯¯
	if successCount == 0 && failedCount > 0 {
		return fmt.Errorf("embedding failed: %v", lastError)
	}

	return nil
}

// ReindexAll é‡æ–°ç´¢å¼•æ‰€æœ‰ bookmark å’Œ file å—
// éå†æ‰€æœ‰æ–‡æ¡£ï¼Œæå– bookmark/file å—ä¿¡æ¯ï¼Œç„¶åé‡æ–°æŠ“å–å’Œç´¢å¼•
func (e *ExternalIndexer) ReindexAll() (int, error) {
	// è·å–æ‰€æœ‰æ–‡æ¡£
	index, err := e.docRepo.GetAll()
	if err != nil {
		return 0, fmt.Errorf("failed to get documents: %w", err)
	}

	totalCount := 0
	for _, doc := range index.Documents {
		// åŠ è½½æ–‡æ¡£å†…å®¹
		content, err := e.docStorage.Load(doc.ID)
		if err != nil {
			fmt.Printf("âš ï¸ [RAG] Failed to load document %s: %v\n", doc.ID, err)
			continue
		}

		// æå–å¤–éƒ¨å—ä¿¡æ¯
		externalIDs := ExtractExternalBlockIDs([]byte(content))

		// é‡æ–°ç´¢å¼• bookmark å—
		for _, bookmark := range externalIDs.BookmarkBlocks {
			if bookmark.URL == "" {
				continue
			}
			if err := e.IndexBookmarkContent(bookmark.URL, doc.ID, bookmark.BlockID); err != nil {
				fmt.Printf("âš ï¸ [RAG] Failed to reindex bookmark %s: %v\n", bookmark.BlockID, err)
			} else {
				totalCount++
				fmt.Printf("âœ… [RAG] Reindexed bookmark: %s\n", bookmark.URL)
			}
		}

		// é‡æ–°ç´¢å¼• file å—
		for _, file := range externalIDs.FileBlocks {
			if file.FilePath == "" {
				continue
			}
			if err := e.IndexFileContent(file.FilePath, doc.ID, file.BlockID); err != nil {
				fmt.Printf("âš ï¸ [RAG] Failed to reindex file %s: %v\n", file.BlockID, err)
			} else {
				totalCount++
				fmt.Printf("âœ… [RAG] Reindexed file: %s\n", file.FilePath)
			}
		}
	}

	return totalCount, nil
}

// ReindexAllWithProgress é‡æ–°ç´¢å¼•æ‰€æœ‰ bookmark å’Œ file å—ï¼ˆå¸¦è¿›åº¦å›è°ƒï¼‰
func (e *ExternalIndexer) ReindexAllWithProgress(onProgress func(current, total int)) (int, error) {
	// è·å–æ‰€æœ‰æ–‡æ¡£å¹¶è®¡ç®—å¤–éƒ¨å—æ€»æ•°
	index, err := e.docRepo.GetAll()
	if err != nil {
		return 0, fmt.Errorf("failed to get documents: %w", err)
	}

	// å…ˆç»Ÿè®¡æ€»æ•°
	var allExternalBlocks []struct {
		docID    string
		bookmark *BookmarkBlockInfo
		file     *FileBlockInfo
	}

	for _, doc := range index.Documents {
		content, err := e.docStorage.Load(doc.ID)
		if err != nil {
			continue
		}
		externalIDs := ExtractExternalBlockIDs([]byte(content))
		for i := range externalIDs.BookmarkBlocks {
			if externalIDs.BookmarkBlocks[i].URL != "" {
				allExternalBlocks = append(allExternalBlocks, struct {
					docID    string
					bookmark *BookmarkBlockInfo
					file     *FileBlockInfo
				}{docID: doc.ID, bookmark: &externalIDs.BookmarkBlocks[i]})
			}
		}
		for i := range externalIDs.FileBlocks {
			if externalIDs.FileBlocks[i].FilePath != "" {
				allExternalBlocks = append(allExternalBlocks, struct {
					docID    string
					bookmark *BookmarkBlockInfo
					file     *FileBlockInfo
				}{docID: doc.ID, file: &externalIDs.FileBlocks[i]})
			}
		}
	}

	total := len(allExternalBlocks)
	if total == 0 {
		return 0, nil
	}

	successCount := 0
	for i, block := range allExternalBlocks {
		// å‘é€è¿›åº¦
		if onProgress != nil {
			onProgress(i+1, total)
		}

		if block.bookmark != nil {
			if err := e.IndexBookmarkContent(block.bookmark.URL, block.docID, block.bookmark.BlockID); err != nil {
				fmt.Printf("âš ï¸ [RAG] Failed to reindex bookmark %s: %v\n", block.bookmark.BlockID, err)
			} else {
				successCount++
				fmt.Printf("âœ… [RAG] Reindexed bookmark: %s\n", block.bookmark.URL)
			}
		} else if block.file != nil {
			if err := e.IndexFileContent(block.file.FilePath, block.docID, block.file.BlockID); err != nil {
				fmt.Printf("âš ï¸ [RAG] Failed to reindex file %s: %v\n", block.file.BlockID, err)
			} else {
				successCount++
				fmt.Printf("âœ… [RAG] Reindexed file: %s\n", block.file.FilePath)
			}
		}
	}

	return successCount, nil
}
